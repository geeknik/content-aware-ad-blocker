{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REPO_ROOT = \"/usr/src/app\"\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import *\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_model(model_type, train_size):\n",
    "    with open(\"%s/model-data/dataset_%s_%d.pickle\" % (REPO_ROOT, model_type, train_size), \"r\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def test_model(dataset, model_type, train_size, model, model_name):\n",
    "    model.fit(dataset[\"X_train\"], dataset[\"Y_train\"])\n",
    "    test_pred = model.predict(dataset[\"X_test\"])\n",
    "    test_y = dataset[\"Y_test\"]\n",
    "    shas = dataset[\"shas_test\"]\n",
    "        \n",
    "    accuracy = (float(sum(test_y == test_pred))) / len(test_pred)\n",
    "    precision = (float(sum((test_y == test_pred) & (test_pred == 1)))) / float(max(1, sum(test_pred == 1)))\n",
    "    recall = (float(sum((test_y == test_pred) & (test_pred == 1)))) / float(sum(test_y == 1))\n",
    "    f1 = 2 * (precision * recall) / max(1, precision + recall)\n",
    "\n",
    "    print \"%10s %15s. Train set size %5d. %0.1f%% / %0.1f%% / %0.1f%% (%0.3f)\" % (\n",
    "        model_type,\n",
    "        model_name,\n",
    "        train_size,\n",
    "        accuracy * 100,\n",
    "        precision * 100,\n",
    "        recall * 100,\n",
    "        f1)\n",
    "        \n",
    "    output_table.append([\n",
    "        model_type,\n",
    "        model_name,\n",
    "        train_size, \n",
    "        accuracy,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "    ])\n",
    "    \n",
    "    # Save 10 errors\n",
    "    error_shas = np.array(shas)[test_y != test_pred][0:50]\n",
    "    error_correct = np.array(test_y)[test_y != test_pred][0:50]\n",
    "    \n",
    "    with open(\"%s/results/model_errors_%s_%s_%d.txt\" % (REPO_ROOT, model_type, model_name, train_size), \"w\") as fout:\n",
    "        for sha, correct in zip(error_shas, error_correct):\n",
    "            fout.write(\"#### %s FLAG: %s ####\\n\\n\" % (sha, \"Yes\" if correct > 0 else \"No\"))\n",
    "            with open(\"%s/scripts/%s.js\" % (REPO_ROOT, sha), \"r\") as fin:\n",
    "                fout.write(fin.read())\n",
    "            fout.write(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var, input_size):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, input_size),\n",
    "                                     input_var=input_var)\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "    \n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "        l_in_drop, num_units=40,\n",
    "        nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "        l_hid1_drop, num_units=15,\n",
    "        nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_hid2_drop, num_units=2,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return l_out\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert np.shape(inputs)[0] == len(targets)\n",
    "    indices = np.arange(np.shape(inputs)[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, np.shape(inputs)[0] - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield inputs[excerpt].toarray(), targets[excerpt]\n",
    "    \n",
    "def test_mlp(dataset, model_type, train_size):\n",
    "    input_var = T.matrix('inputs')\n",
    "    target_var = T.lvector('targets')\n",
    "    # Create neural network model\n",
    "    network = build_mlp(input_var, np.shape(dataset[\"X_train\"])[1])\n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.adam(loss, params)\n",
    "    \n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    \n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "    \n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    \n",
    "    X_train_flat = dataset[\"X_train\"].tocsc()\n",
    "    X_test_flat = dataset[\"X_test\"].tocsc()\n",
    "\n",
    "    best_accuracy = 0\n",
    "    bad_count = 0\n",
    "    batch_size = min(200, train_size/10)\n",
    "    for epoch in xrange(999):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train_flat, dataset[\"Y_train\"], batch_size, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_test_flat, dataset[\"Y_test\"], batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        \n",
    "        current_accuracy = val_acc / val_batches\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} took {:.3f}s - accuracy {:.2f} %\".format(\n",
    "            epoch + 1, time.time() - start_time, current_accuracy * 100))\n",
    "        \n",
    "        if current_accuracy > best_accuracy:\n",
    "            best_accuracy = current_accuracy\n",
    "            bad_count = 0\n",
    "        else:\n",
    "            bad_count += 1\n",
    "            if bad_count > 4:\n",
    "                break\n",
    "        \n",
    "    print \"%10s %15s. Train set size %5d. %0.1f%% / %0.1f%% / %0.1f%% (%0.3f)\" % (\n",
    "            model_type,\n",
    "            \"MLP\",\n",
    "            train_size,\n",
    "            current_accuracy * 100,\n",
    "            0,\n",
    "            0,\n",
    "            0)\n",
    "    output_table.append([\n",
    "            model_type,\n",
    "            \"MLP\",\n",
    "            train_size, \n",
    "            current_accuracy,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sizes: [300, 600, 1200, 2400, 4800, 9600, 19200]\n",
      "Test size: 3588\n"
     ]
    }
   ],
   "source": [
    "with open(\"%s/model-data/metadata.pickle\" % (REPO_ROOT,), \"r\") as f:\n",
    "    size_data = pickle.load(f)\n",
    "    \n",
    "TRAIN_SIZES = size_data[\"train_sizes\"]\n",
    "TEST_SIZE = size_data[\"test_size\"]\n",
    "\n",
    "print \"Training sizes: %s\" % TRAIN_SIZES\n",
    "print \"Test size: %d\" % TEST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RegEx             KNN. Train set size   300. 76.6% / 84.6% / 65.1% (0.736)\n",
      "     RegEx       Bernoulli. Train set size   300. 58.7% / 54.9% / 97.0% (0.701)\n",
      "     RegEx             SGD. Train set size   300. 79.8% / 84.1% / 73.6% (0.785)\n",
      "     RegEx    RandomForest. Train set size   300. 70.2% / 64.2% / 91.4% (0.754)\n",
      "     RegEx       LinearSVC. Train set size   300. 79.1% / 84.2% / 71.7% (0.775)\n",
      "   BiRegEx             KNN. Train set size   300. 77.2% / 82.7% / 68.9% (0.752)\n",
      "   BiRegEx       Bernoulli. Train set size   300. 58.6% / 54.9% / 97.1% (0.701)\n",
      "   BiRegEx             SGD. Train set size   300. 79.8% / 82.7% / 75.5% (0.789)\n",
      "   BiRegEx    RandomForest. Train set size   300. 70.3% / 64.5% / 90.1% (0.752)\n",
      "   BiRegEx       LinearSVC. Train set size   300. 78.6% / 82.7% / 72.4% (0.772)\n",
      "  TriRegEx             KNN. Train set size   300. 78.2% / 83.8% / 70.0% (0.763)\n",
      "  TriRegEx       Bernoulli. Train set size   300. 58.3% / 54.7% / 96.5% (0.699)\n",
      "  TriRegEx             SGD. Train set size   300. 80.5% / 83.1% / 76.6% (0.798)\n",
      "  TriRegEx    RandomForest. Train set size   300. 74.4% / 70.2% / 84.9% (0.769)\n",
      "  TriRegEx       LinearSVC. Train set size   300. 79.9% / 84.1% / 73.7% (0.786)\n",
      "       AST             KNN. Train set size   300. 76.1% / 80.6% / 68.7% (0.742)\n",
      "       AST       Bernoulli. Train set size   300. 57.1% / 53.9% / 97.7% (0.695)\n",
      "       AST             SGD. Train set size   300. 78.0% / 79.4% / 75.7% (0.775)\n",
      "       AST    RandomForest. Train set size   300. 68.8% / 63.2% / 89.6% (0.742)\n",
      "       AST       LinearSVC. Train set size   300. 78.3% / 80.6% / 74.6% (0.775)\n",
      "     BiAST             KNN. Train set size   300. 78.1% / 82.1% / 71.9% (0.766)\n",
      "     BiAST       Bernoulli. Train set size   300. 57.1% / 54.0% / 96.1% (0.691)\n",
      "     BiAST             SGD. Train set size   300. 79.3% / 82.0% / 75.3% (0.785)\n",
      "     BiAST    RandomForest. Train set size   300. 70.1% / 65.6% / 84.6% (0.739)\n",
      "     BiAST       LinearSVC. Train set size   300. 79.5% / 82.7% / 74.7% (0.785)\n",
      "    TriAST             KNN. Train set size   300. 77.9% / 81.7% / 71.9% (0.765)\n",
      "    TriAST       Bernoulli. Train set size   300. 57.1% / 54.1% / 94.5% (0.688)\n",
      "    TriAST             SGD. Train set size   300. 79.8% / 82.6% / 75.4% (0.788)\n",
      "    TriAST    RandomForest. Train set size   300. 73.3% / 70.3% / 80.7% (0.751)\n",
      "    TriAST       LinearSVC. Train set size   300. 79.6% / 82.9% / 74.7% (0.786)\n",
      "     RegEx             KNN. Train set size   600. 80.1% / 86.5% / 71.2% (0.781)\n",
      "     RegEx       Bernoulli. Train set size   600. 62.1% / 57.3% / 94.9% (0.715)\n",
      "     RegEx             SGD. Train set size   600. 81.9% / 86.2% / 75.9% (0.807)\n",
      "     RegEx    RandomForest. Train set size   600. 69.5% / 63.4% / 92.1% (0.751)\n",
      "     RegEx       LinearSVC. Train set size   600. 81.7% / 86.6% / 75.0% (0.804)\n",
      "   BiRegEx             KNN. Train set size   600. 80.5% / 85.6% / 73.4% (0.790)\n",
      "   BiRegEx       Bernoulli. Train set size   600. 61.0% / 56.5% / 95.8% (0.710)\n",
      "   BiRegEx             SGD. Train set size   600. 81.2% / 85.3% / 75.5% (0.801)\n",
      "   BiRegEx    RandomForest. Train set size   600. 73.2% / 67.7% / 89.1% (0.769)\n",
      "   BiRegEx       LinearSVC. Train set size   600. 81.2% / 86.3% / 74.2% (0.798)\n",
      "  TriRegEx             KNN. Train set size   600. 80.3% / 84.9% / 73.6% (0.789)\n",
      "  TriRegEx       Bernoulli. Train set size   600. 60.8% / 56.3% / 95.9% (0.710)\n",
      "  TriRegEx             SGD. Train set size   600. 82.1% / 86.3% / 76.3% (0.810)\n",
      "  TriRegEx    RandomForest. Train set size   600. 76.9% / 73.2% / 84.9% (0.786)\n",
      "  TriRegEx       LinearSVC. Train set size   600. 81.8% / 87.3% / 74.5% (0.804)\n",
      "       AST             KNN. Train set size   600. 78.1% / 89.9% / 63.2% (0.742)\n",
      "       AST       Bernoulli. Train set size   600. 57.7% / 54.3% / 97.6% (0.698)\n",
      "       AST             SGD. Train set size   600. 81.2% / 84.8% / 76.0% (0.802)\n",
      "       AST    RandomForest. Train set size   600. 68.9% / 63.1% / 91.4% (0.746)\n",
      "       AST       LinearSVC. Train set size   600. 81.1% / 85.8% / 74.5% (0.797)\n",
      "     BiAST             KNN. Train set size   600. 79.5% / 93.4% / 63.4% (0.756)\n",
      "     BiAST       Bernoulli. Train set size   600. 58.4% / 54.8% / 96.0% (0.698)\n",
      "     BiAST             SGD. Train set size   600. 81.6% / 86.2% / 75.1% (0.803)\n",
      "     BiAST    RandomForest. Train set size   600. 73.3% / 68.8% / 85.2% (0.761)\n",
      "     BiAST       LinearSVC. Train set size   600. 82.1% / 87.9% / 74.6% (0.807)\n",
      "    TriAST             KNN. Train set size   600. 79.0% / 94.4% / 61.7% (0.746)\n",
      "    TriAST       Bernoulli. Train set size   600. 59.0% / 55.3% / 94.3% (0.697)\n",
      "    TriAST             SGD. Train set size   600. 82.0% / 86.9% / 75.3% (0.807)\n",
      "    TriAST    RandomForest. Train set size   600. 75.4% / 72.9% / 80.7% (0.766)\n",
      "    TriAST       LinearSVC. Train set size   600. 82.5% / 88.6% / 74.6% (0.810)\n",
      "     RegEx             KNN. Train set size  1200. 81.1% / 83.4% / 77.6% (0.804)\n",
      "     RegEx       Bernoulli. Train set size  1200. 63.6% / 58.3% / 95.3% (0.723)\n",
      "     RegEx             SGD. Train set size  1200. 82.9% / 87.4% / 76.8% (0.818)\n",
      "     RegEx    RandomForest. Train set size  1200. 70.2% / 64.0% / 92.1% (0.755)\n",
      "     RegEx       LinearSVC. Train set size  1200. 83.4% / 88.6% / 76.8% (0.823)\n",
      "   BiRegEx             KNN. Train set size  1200. 77.3% / 74.4% / 83.1% (0.785)\n",
      "   BiRegEx       Bernoulli. Train set size  1200. 62.7% / 57.7% / 95.4% (0.719)\n",
      "   BiRegEx             SGD. Train set size  1200. 83.5% / 87.6% / 78.0% (0.825)\n",
      "   BiRegEx    RandomForest. Train set size  1200. 74.6% / 68.9% / 89.5% (0.779)\n",
      "   BiRegEx       LinearSVC. Train set size  1200. 84.2% / 89.0% / 78.1% (0.832)\n",
      "  TriRegEx             KNN. Train set size  1200. 75.0% / 70.5% / 86.0% (0.775)\n",
      "  TriRegEx       Bernoulli. Train set size  1200. 62.4% / 57.5% / 94.8% (0.716)\n",
      "  TriRegEx             SGD. Train set size  1200. 84.7% / 89.1% / 79.1% (0.838)\n",
      "  TriRegEx    RandomForest. Train set size  1200. 76.8% / 72.5% / 86.4% (0.788)\n",
      "  TriRegEx       LinearSVC. Train set size  1200. 85.5% / 90.7% / 79.0% (0.844)\n",
      "       AST             KNN. Train set size  1200. 81.5% / 92.9% / 68.3% (0.787)\n",
      "       AST       Bernoulli. Train set size  1200. 60.6% / 56.2% / 97.2% (0.712)\n",
      "       AST             SGD. Train set size  1200. 83.6% / 87.6% / 78.1% (0.826)\n",
      "       AST    RandomForest. Train set size  1200. 71.5% / 65.6% / 90.2% (0.760)\n",
      "       AST       LinearSVC. Train set size  1200. 84.4% / 89.5% / 78.0% (0.833)\n",
      "     BiAST             KNN. Train set size  1200. 81.9% / 94.8% / 67.4% (0.788)\n",
      "     BiAST       Bernoulli. Train set size  1200. 60.7% / 56.4% / 94.8% (0.707)\n",
      "     BiAST             SGD. Train set size  1200. 84.3% / 88.6% / 78.6% (0.833)\n",
      "     BiAST    RandomForest. Train set size  1200. 71.5% / 66.5% / 86.8% (0.753)\n",
      "     BiAST       LinearSVC. Train set size  1200. 85.1% / 90.5% / 78.4% (0.840)\n",
      "    TriAST             KNN. Train set size  1200. 81.7% / 95.4% / 66.7% (0.785)\n",
      "    TriAST       Bernoulli. Train set size  1200. 60.5% / 56.4% / 93.0% (0.702)\n",
      "    TriAST             SGD. Train set size  1200. 84.6% / 89.3% / 78.7% (0.836)\n",
      "    TriAST    RandomForest. Train set size  1200. 76.2% / 72.8% / 83.7% (0.779)\n",
      "    TriAST       LinearSVC. Train set size  1200. 85.3% / 90.9% / 78.4% (0.842)\n",
      "     RegEx             KNN. Train set size  2400. 82.4% / 84.2% / 79.6% (0.819)\n",
      "     RegEx       Bernoulli. Train set size  2400. 64.7% / 59.2% / 94.9% (0.729)\n",
      "     RegEx             SGD. Train set size  2400. 84.1% / 87.6% / 79.4% (0.833)\n",
      "     RegEx    RandomForest. Train set size  2400. 70.1% / 64.0% / 91.7% (0.754)\n",
      "     RegEx       LinearSVC. Train set size  2400. 86.4% / 90.1% / 81.7% (0.857)\n",
      "   BiRegEx             KNN. Train set size  2400. 78.9% / 76.2% / 84.2% (0.800)\n",
      "   BiRegEx       Bernoulli. Train set size  2400. 63.5% / 58.3% / 95.0% (0.722)\n",
      "   BiRegEx             SGD. Train set size  2400. 85.4% / 89.1% / 80.7% (0.847)\n",
      "   BiRegEx    RandomForest. Train set size  2400. 74.3% / 68.4% / 90.2% (0.778)\n",
      "   BiRegEx       LinearSVC. Train set size  2400. 87.0% / 92.0% / 81.1% (0.862)\n",
      "  TriRegEx             KNN. Train set size  2400. 77.5% / 73.2% / 87.0% (0.795)\n",
      "  TriRegEx       Bernoulli. Train set size  2400. 63.3% / 58.2% / 94.5% (0.720)\n",
      "  TriRegEx             SGD. Train set size  2400. 86.4% / 91.1% / 80.6% (0.855)\n",
      "  TriRegEx    RandomForest. Train set size  2400. 77.3% / 72.9% / 87.1% (0.794)\n",
      "  TriRegEx       LinearSVC. Train set size  2400. 87.7% / 92.9% / 81.7% (0.869)\n",
      "       AST             KNN. Train set size  2400. 83.0% / 93.7% / 70.8% (0.807)\n",
      "       AST       Bernoulli. Train set size  2400. 62.6% / 57.5% / 96.7% (0.721)\n",
      "       AST             SGD. Train set size  2400. 84.6% / 87.7% / 80.4% (0.839)\n",
      "       AST    RandomForest. Train set size  2400. 71.6% / 66.0% / 88.9% (0.758)\n",
      "       AST       LinearSVC. Train set size  2400. 85.9% / 90.0% / 80.8% (0.851)\n",
      "     BiAST             KNN. Train set size  2400. 83.9% / 96.2% / 70.6% (0.814)\n",
      "     BiAST       Bernoulli. Train set size  2400. 62.1% / 57.4% / 94.0% (0.713)\n",
      "     BiAST             SGD. Train set size  2400. 85.2% / 88.5% / 80.9% (0.845)\n",
      "     BiAST    RandomForest. Train set size  2400. 73.8% / 69.1% / 86.2% (0.767)\n",
      "     BiAST       LinearSVC. Train set size  2400. 86.9% / 91.0% / 81.8% (0.862)\n",
      "    TriAST             KNN. Train set size  2400. 83.8% / 96.4% / 70.3% (0.813)\n",
      "    TriAST       Bernoulli. Train set size  2400. 61.5% / 57.1% / 92.5% (0.706)\n",
      "    TriAST             SGD. Train set size  2400. 85.7% / 89.2% / 81.3% (0.851)\n",
      "    TriAST    RandomForest. Train set size  2400. 76.3% / 72.2% / 85.6% (0.783)\n",
      "    TriAST       LinearSVC. Train set size  2400. 87.2% / 91.4% / 82.2% (0.866)\n",
      "     RegEx             KNN. Train set size  4800. 84.5% / 86.4% / 81.9% (0.841)\n",
      "     RegEx       Bernoulli. Train set size  4800. 65.4% / 59.7% / 94.4% (0.731)\n",
      "     RegEx             SGD. Train set size  4800. 84.9% / 89.1% / 79.6% (0.841)\n",
      "     RegEx    RandomForest. Train set size  4800. 68.3% / 62.2% / 93.1% (0.746)\n",
      "     RegEx       LinearSVC. Train set size  4800. 88.2% / 92.4% / 83.3% (0.876)\n",
      "   BiRegEx             KNN. Train set size  4800. 81.9% / 79.7% / 85.8% (0.826)\n",
      "   BiRegEx       Bernoulli. Train set size  4800. 64.4% / 58.9% / 94.7% (0.727)\n",
      "   BiRegEx             SGD. Train set size  4800. 86.8% / 92.1% / 80.4% (0.859)\n",
      "   BiRegEx    RandomForest. Train set size  4800. 73.7% / 67.9% / 89.8% (0.773)\n",
      "   BiRegEx       LinearSVC. Train set size  4800. 89.3% / 93.3% / 84.6% (0.887)\n",
      "  TriRegEx             KNN. Train set size  4800. 80.4% / 76.4% / 88.0% (0.818)\n",
      "  TriRegEx       Bernoulli. Train set size  4800. 64.2% / 58.9% / 94.3% (0.725)\n",
      "  TriRegEx             SGD. Train set size  4800. 87.9% / 93.0% / 81.9% (0.871)\n",
      "  TriRegEx    RandomForest. Train set size  4800. 77.9% / 73.5% / 87.2% (0.798)\n",
      "  TriRegEx       LinearSVC. Train set size  4800. 89.6% / 93.4% / 85.2% (0.891)\n",
      "       AST             KNN. Train set size  4800. 84.7% / 95.0% / 73.3% (0.828)\n",
      "       AST       Bernoulli. Train set size  4800. 63.9% / 58.4% / 96.6% (0.728)\n",
      "       AST             SGD. Train set size  4800. 86.2% / 90.1% / 81.4% (0.855)\n",
      "       AST    RandomForest. Train set size  4800. 70.2% / 64.2% / 91.4% (0.754)\n",
      "       AST       LinearSVC. Train set size  4800. 88.3% / 91.4% / 84.6% (0.879)\n",
      "     BiAST             KNN. Train set size  4800. 85.5% / 96.6% / 73.6% (0.836)\n",
      "     BiAST       Bernoulli. Train set size  4800. 62.9% / 58.0% / 93.8% (0.717)\n",
      "     BiAST             SGD. Train set size  4800. 87.9% / 91.9% / 83.1% (0.873)\n",
      "     BiAST    RandomForest. Train set size  4800. 74.5% / 69.3% / 87.8% (0.775)\n",
      "     BiAST       LinearSVC. Train set size  4800. 89.4% / 92.5% / 85.8% (0.890)\n",
      "    TriAST             KNN. Train set size  4800. 85.4% / 96.5% / 73.5% (0.835)\n",
      "    TriAST       Bernoulli. Train set size  4800. 61.8% / 57.4% / 91.8% (0.706)\n",
      "    TriAST             SGD. Train set size  4800. 88.0% / 92.2% / 83.1% (0.874)\n",
      "    TriAST    RandomForest. Train set size  4800. 76.6% / 72.2% / 86.5% (0.787)\n",
      "    TriAST       LinearSVC. Train set size  4800. 89.7% / 92.7% / 86.1% (0.893)\n",
      "     RegEx             KNN. Train set size  9600. 86.3% / 87.8% / 84.3% (0.860)\n",
      "     RegEx       Bernoulli. Train set size  9600. 66.3% / 60.5% / 94.1% (0.736)\n",
      "     RegEx             SGD. Train set size  9600. 84.9% / 89.0% / 79.6% (0.840)\n",
      "     RegEx    RandomForest. Train set size  9600. 70.9% / 64.6% / 92.5% (0.761)\n",
      "     RegEx       LinearSVC. Train set size  9600. 89.4% / 93.3% / 84.8% (0.888)\n",
      "   BiRegEx             KNN. Train set size  9600. 84.3% / 82.1% / 87.8% (0.849)\n",
      "   BiRegEx       Bernoulli. Train set size  9600. 65.2% / 59.6% / 94.2% (0.730)\n",
      "   BiRegEx             SGD. Train set size  9600. 87.1% / 92.1% / 81.0% (0.862)\n",
      "   BiRegEx    RandomForest. Train set size  9600. 76.2% / 70.2% / 91.0% (0.792)\n",
      "   BiRegEx       LinearSVC. Train set size  9600. 90.8% / 94.1% / 87.0% (0.904)\n",
      "  TriRegEx             KNN. Train set size  9600. 82.8% / 78.7% / 89.9% (0.839)\n",
      "  TriRegEx       Bernoulli. Train set size  9600. 64.8% / 59.4% / 93.6% (0.727)\n",
      "  TriRegEx             SGD. Train set size  9600. 88.0% / 93.2% / 82.0% (0.872)\n",
      "  TriRegEx    RandomForest. Train set size  9600. 77.7% / 73.0% / 88.0% (0.798)\n",
      "  TriRegEx       LinearSVC. Train set size  9600. 91.1% / 94.2% / 87.7% (0.908)\n",
      "       AST             KNN. Train set size  9600. 86.7% / 96.2% / 76.5% (0.852)\n",
      "       AST       Bernoulli. Train set size  9600. 65.1% / 59.3% / 96.0% (0.733)\n",
      "       AST             SGD. Train set size  9600. 86.8% / 90.7% / 82.1% (0.862)\n",
      "       AST    RandomForest. Train set size  9600. 70.1% / 64.0% / 91.7% (0.754)\n",
      "       AST       LinearSVC. Train set size  9600. 90.0% / 92.4% / 87.1% (0.897)\n",
      "     BiAST             KNN. Train set size  9600. 86.6% / 96.7% / 75.7% (0.849)\n",
      "     BiAST       Bernoulli. Train set size  9600. 63.5% / 58.5% / 92.9% (0.718)\n",
      "     BiAST             SGD. Train set size  9600. 87.9% / 92.5% / 82.4% (0.872)\n",
      "     BiAST    RandomForest. Train set size  9600. 74.9% / 70.4% / 86.1% (0.774)\n",
      "     BiAST       LinearSVC. Train set size  9600. 90.4% / 92.9% / 87.4% (0.901)\n",
      "    TriAST             KNN. Train set size  9600. 86.9% / 97.0% / 76.2% (0.853)\n",
      "    TriAST       Bernoulli. Train set size  9600. 62.4% / 57.8% / 91.7% (0.709)\n",
      "    TriAST             SGD. Train set size  9600. 88.5% / 93.0% / 83.2% (0.878)\n",
      "    TriAST    RandomForest. Train set size  9600. 77.4% / 72.5% / 88.3% (0.796)\n",
      "    TriAST       LinearSVC. Train set size  9600. 90.5% / 93.3% / 87.3% (0.902)\n",
      "     RegEx             KNN. Train set size 19200. 88.0% / 89.6% / 85.9% (0.877)\n",
      "     RegEx       Bernoulli. Train set size 19200. 66.9% / 60.9% / 94.2% (0.740)\n",
      "     RegEx             SGD. Train set size 19200. 85.3% / 89.9% / 79.5% (0.844)\n",
      "     RegEx    RandomForest. Train set size 19200. 70.2% / 63.9% / 92.9% (0.757)\n",
      "     RegEx       LinearSVC. Train set size 19200. 90.9% / 94.3% / 87.0% (0.905)\n",
      "   BiRegEx             KNN. Train set size 19200. 85.7% / 83.7% / 88.7% (0.861)\n",
      "   BiRegEx       Bernoulli. Train set size 19200. 66.1% / 60.3% / 94.0% (0.735)\n",
      "   BiRegEx             SGD. Train set size 19200. 87.1% / 92.6% / 80.5% (0.862)\n",
      "   BiRegEx    RandomForest. Train set size 19200. 76.3% / 70.4% / 90.6% (0.792)\n",
      "   BiRegEx       LinearSVC. Train set size 19200. 92.0% / 94.6% / 89.1% (0.918)\n",
      "  TriRegEx             KNN. Train set size 19200. 84.7% / 81.1% / 90.5% (0.856)\n",
      "  TriRegEx       Bernoulli. Train set size 19200. 65.2% / 59.7% / 93.3% (0.728)\n",
      "  TriRegEx             SGD. Train set size 19200. 88.1% / 93.8% / 81.5% (0.872)\n",
      "  TriRegEx    RandomForest. Train set size 19200. 79.1% / 74.5% / 88.4% (0.808)\n",
      "  TriRegEx       LinearSVC. Train set size 19200. 92.0% / 94.3% / 89.5% (0.918)\n",
      "       AST             KNN. Train set size 19200. 88.0% / 96.7% / 78.7% (0.868)\n",
      "       AST       Bernoulli. Train set size 19200. 65.9% / 60.0% / 95.8% (0.737)\n",
      "       AST             SGD. Train set size 19200. 87.3% / 91.8% / 82.0% (0.866)\n",
      "       AST    RandomForest. Train set size 19200. 71.7% / 65.5% / 91.8% (0.764)\n",
      "       AST       LinearSVC. Train set size 19200. 91.6% / 93.6% / 89.4% (0.914)\n",
      "     BiAST             KNN. Train set size 19200. 88.1% / 97.1% / 78.5% (0.868)\n",
      "     BiAST       Bernoulli. Train set size 19200. 64.1% / 58.9% / 92.9% (0.721)\n",
      "     BiAST             SGD. Train set size 19200. 88.4% / 93.2% / 82.9% (0.877)\n",
      "     BiAST    RandomForest. Train set size 19200. 74.5% / 69.0% / 89.0% (0.777)\n",
      "     BiAST       LinearSVC. Train set size 19200. 91.6% / 93.8% / 89.0% (0.914)\n",
      "    TriAST             KNN. Train set size 19200. 87.9% / 96.9% / 78.3% (0.866)\n",
      "    TriAST       Bernoulli. Train set size 19200. 62.5% / 57.9% / 91.5% (0.709)\n",
      "    TriAST             SGD. Train set size 19200. 88.6% / 93.2% / 83.3% (0.880)\n",
      "    TriAST    RandomForest. Train set size 19200. 76.6% / 71.5% / 88.4% (0.790)\n",
      "    TriAST       LinearSVC. Train set size 19200. 91.8% / 94.1% / 89.2% (0.916)\n"
     ]
    }
   ],
   "source": [
    "output_table = []\n",
    "\n",
    "for train_size in TRAIN_SIZES:\n",
    "    for model_type in [\"RegEx\", \"BiRegEx\", \"TriRegEx\", \"AST\", \"BiAST\", \"TriAST\"]:\n",
    "        dataset = load_model(model_type, train_size)\n",
    "\n",
    "        test_model(dataset, model_type, train_size,\n",
    "                   KNeighborsClassifier(2), \"KNN\")\n",
    "        \n",
    "        test_model(dataset, model_type, train_size,\n",
    "                   BernoulliNB(), \"Bernoulli\")\n",
    "\n",
    "        test_model(dataset, model_type, train_size,\n",
    "                   linear_model.SGDClassifier(n_iter=1000, loss=\"log\"), \"SGD\")\n",
    "        \n",
    "        test_model(dataset, model_type, train_size,\n",
    "                   RandomForestClassifier(max_depth=15, n_estimators=100, max_features=30), \"RandomForest\")\n",
    "        \n",
    "        test_model(dataset, model_type, train_size,\n",
    "                   LinearSVC(), \"LinearSVC\")\n",
    "        \n",
    "        #test_mlp(dataset, model_type, train_size)\n",
    "        \n",
    "output = (\"Model Type,Model,Training set,Accuracy,Precision,Recall,F1 score\\n\" +\n",
    "        \"\\n\".join([\",\".join([str(s) for s in row]) for row in output_table]))\n",
    "with open(\"%s/results/linear_models.csv\" % REPO_ROOT, \"w\") as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
